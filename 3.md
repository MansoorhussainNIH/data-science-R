
#Data Science Using R
##3 - Getting and Cleaning Data

###0) R version used

```r
print(R.version.string)
```

```
## [1] "R version 3.2.3 (2015-12-10)"
```

###1) downloading/reading-local/reading-xls/reading-XML/XPath/JSON/data.table

```r
# downloading
if(!file.exists("data")){ dir.create("data") }

# reading local
if(!file.exists("data/cameras.csv")){
    fileUrl<-"https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
    download.file(fileUrl,destfile="./data/cameras.csv",method="curl")
}
cameraData<-read.table("./data/cameras.csv",sep=",",header=TRUE)
head(cameraData,2)
```

```
##                    address direction    street crossStreet
## 1 S CATON AVE & BENSON AVE       N/B Caton Ave  Benson Ave
## 2 S CATON AVE & BENSON AVE       S/B Caton Ave  Benson Ave
##             intersection                      Location.1
## 1 Caton Ave & Benson Ave (39.2693779962, -76.6688185297)
## 2 Caton Ave & Benson Ave (39.2693157898, -76.6689698176)
```

```r
str(cameraData)
```

```
## 'data.frame':	80 obs. of  6 variables:
##  $ address     : Factor w/ 71 levels "E 33RD ST & THE ALAMEDA",..: 49 49 70 57 1 14 14 31 5 35 ...
##  $ direction   : Factor w/ 4 levels "E/B","N/B","S/B",..: 2 3 1 3 1 1 4 3 4 1 ...
##  $ street      : Factor w/ 55 levels "Caton Ave","Charles",..: 1 1 54 50 4 8 8 2 26 33 ...
##  $ crossStreet : Factor w/ 66 levels "33rd St","4th St",..: 6 6 49 1 58 40 40 36 7 38 ...
##  $ intersection: Factor w/ 74 levels " &","Caton Ave & Benson Ave",..: 2 2 73 69 7 13 13 3 35 47 ...
##  $ Location.1  : Factor w/ 76 levels "(39.1999130165, -76.5559766825)",..: 7 6 8 49 48 35 36 74 32 29 ...
```

```r
# reading xls
if(!file.exists("data/cameras.xlsx")){
    fileUrl<-"https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
    download.file(fileUrl,destfile="./data/cameras.xlsx",method="curl")
}

if(!require(xlsx)){
  install.packages("xlsx",repo="https://cran.rstudio.com/")
}
library(xlsx)
cameraData<-read.xlsx("./data/cameras.xlsx",sheetIndex=1,header=TRUE)
head(cameraData,2)
```

```
##                    address direction    street crossStreet
## 1 S CATON AVE & BENSON AVE       N/B Caton Ave  Benson Ave
## 2 S CATON AVE & BENSON AVE       S/B Caton Ave  Benson Ave
##             intersection                      Location.1
## 1 Caton Ave & Benson Ave (39.2693779962, -76.6688185297)
## 2 Caton Ave & Benson Ave (39.2693157898, -76.6689698176)
```

```r
str(cameraData)
```

```
## 'data.frame':	80 obs. of  6 variables:
##  $ address     : Factor w/ 71 levels "E 33RD ST & THE ALAMEDA",..: 49 49 70 57 1 14 14 31 5 35 ...
##  $ direction   : Factor w/ 4 levels "E/B","N/B","S/B",..: 2 3 1 3 1 1 4 3 4 1 ...
##  $ street      : Factor w/ 55 levels "Caton Ave","Charles",..: 1 1 54 50 4 8 8 2 26 33 ...
##  $ crossStreet : Factor w/ 66 levels "33rd St","4th St",..: 6 6 49 1 58 40 40 36 7 38 ...
##  $ intersection: Factor w/ 74 levels " &","Caton Ave & Benson Ave",..: 2 2 73 69 7 13 13 3 35 47 ...
##  $ Location.1  : Factor w/ 76 levels "(39.1999130165, -76.5559766825)",..: 7 6 8 49 48 35 36 74 32 29 ...
```

```r
cameraDataSubset<-read.xlsx("./data/cameras.xlsx",sheetIndex=1,colIndex=2:3,rowIndex=1:4)
head(cameraDataSubset,2)
```

```
##   direction    street
## 1       N/B Caton Ave
## 2       S/B Caton Ave
```

```r
str(cameraDataSubset)
```

```
## 'data.frame':	3 obs. of  2 variables:
##  $ direction: Factor w/ 3 levels "E/B","N/B","S/B": 2 3 1
##  $ street   : Factor w/ 2 levels "Caton Ave","Wilkens Ave": 1 1 2
```

```r
# reading XML
if(!file.exists("data/simple.xml")){
    fileUrl<-"http://www.w3schools.com/xml/simple.xml"
    download.file(fileUrl,destfile="./data/simple.xml",method="curl")
}
if(!require(XML)){
  install.packages("XML",repo="https://cran.rstudio.com/")
}
library(XML)
doc<-xmlTreeParse("./data/simple.xml",useInternal=TRUE)
rootNode<-xmlRoot(doc)
names(rootNode[[1]])
```

```
##          name         price   description      calories 
##        "name"       "price" "description"    "calories"
```

```r
rootNode[[1]]
```

```
## <food>
##   <name>Belgian Waffles</name>
##   <price>$5.95</price>
##   <description>Two of our famous Belgian Waffles with plenty of real maple syrup</description>
##   <calories>650</calories>
## </food>
```

```r
rootNode[[1]][[2]]
```

```
## <price>$5.95</price>
```

```r
# programmatically extracting parts of file
xmlSApply(rootNode,xmlValue)
```

```
##                                                                                                                     food 
##                               "Belgian Waffles$5.95Two of our famous Belgian Waffles with plenty of real maple syrup650" 
##                                                                                                                     food 
##                    "Strawberry Belgian Waffles$7.95Light Belgian waffles covered with strawberries and whipped cream900" 
##                                                                                                                     food 
## "Berry-Berry Belgian Waffles$8.95Light Belgian waffles covered with an assortment of fresh berries and whipped cream900" 
##                                                                                                                     food 
##                                                "French Toast$4.50Thick slices made from our homemade sourdough bread600" 
##                                                                                                                     food 
##                         "Homestyle Breakfast$6.95Two eggs, bacon or sausage, toast, and our ever-popular hash browns950"
```

```r
# get the item menu/price using XPath
xpathSApply(rootNode,"//name",xmlValue)
```

```
## [1] "Belgian Waffles"             "Strawberry Belgian Waffles" 
## [3] "Berry-Berry Belgian Waffles" "French Toast"               
## [5] "Homestyle Breakfast"
```

```r
xpathSApply(rootNode,"//price",xmlValue)
```

```
## [1] "$5.95" "$7.95" "$8.95" "$4.50" "$6.95"
```

```r
# extract content by attributes using XPath
if(!file.exists("data/baltimore-ravens.html")){
    fileUrl<-"http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
    download.file(fileUrl,destfile="./data/baltimore-ravens.html",method="curl")
}
doc<-htmlTreeParse("./data/baltimore-ravens.html",useInternal=TRUE)
xpathSApply(doc,"//li[@class='team-name']",xmlValue)
```

```
## [1] "Baltimore RavensRavens" "Baltimore RavensRavens"
```

```r
# reading JSON
if(!file.exists("data/jtleek.json")){
    fileUrl<-"https://api.github.com/users/jtleek/repos"
    download.file(fileUrl,destfile="./data/jtleek.json",method="curl")
}
if(!require(jsonlite)){
  install.packages("jsonlite",repo="https://cran.rstudio.com/")
}
library(jsonlite)
jsonData<-fromJSON("./data/jtleek.json")
names(jsonData)
```

```
##  [1] "id"                "name"              "full_name"        
##  [4] "owner"             "private"           "html_url"         
##  [7] "description"       "fork"              "url"              
## [10] "forks_url"         "keys_url"          "collaborators_url"
## [13] "teams_url"         "hooks_url"         "issue_events_url" 
## [16] "events_url"        "assignees_url"     "branches_url"     
## [19] "tags_url"          "blobs_url"         "git_tags_url"     
## [22] "git_refs_url"      "trees_url"         "statuses_url"     
## [25] "languages_url"     "stargazers_url"    "contributors_url" 
## [28] "subscribers_url"   "subscription_url"  "commits_url"      
## [31] "git_commits_url"   "comments_url"      "issue_comment_url"
## [34] "contents_url"      "compare_url"       "merges_url"       
## [37] "archive_url"       "downloads_url"     "issues_url"       
## [40] "pulls_url"         "milestones_url"    "notifications_url"
## [43] "labels_url"        "releases_url"      "deployments_url"  
## [46] "created_at"        "updated_at"        "pushed_at"        
## [49] "git_url"           "ssh_url"           "clone_url"        
## [52] "svn_url"           "homepage"          "size"             
## [55] "stargazers_count"  "watchers_count"    "language"         
## [58] "has_issues"        "has_downloads"     "has_wiki"         
## [61] "has_pages"         "forks_count"       "mirror_url"       
## [64] "open_issues_count" "forks"             "open_issues"      
## [67] "watchers"          "default_branch"
```

```r
#nested objects JSON
library(datasets)
names(jsonData$owner)
```

```
##  [1] "login"               "id"                  "avatar_url"         
##  [4] "gravatar_id"         "url"                 "html_url"           
##  [7] "followers_url"       "following_url"       "gists_url"          
## [10] "starred_url"         "subscriptions_url"   "organizations_url"  
## [13] "repos_url"           "events_url"          "received_events_url"
## [16] "type"                "site_admin"
```

```r
testjson<-toJSON(data.frame(foo=1:4,bar=c(T,T,F,F)),pretty=TRUE)
testjson
```

```
## [
##   {
##     "foo": 1,
##     "bar": true
##   },
##   {
##     "foo": 2,
##     "bar": true
##   },
##   {
##     "foo": 3,
##     "bar": false
##   },
##   {
##     "foo": 4,
##     "bar": false
##   }
## ]
```

```r
head(fromJSON(testjson))
```

```
##   foo   bar
## 1   1  TRUE
## 2   2  TRUE
## 3   3 FALSE
## 4   4 FALSE
```

```r
# data.table (written in C / VERY FAST)
# inherits from data.frame
if(!require(data.table)){
  install.packages("data.table",repo="https://cran.rstudio.com/")
}
library(data.table)
set.seed(37)
df=data.frame(x=rbinom(5,2,0.5),y=rep(c("a","b","c","d","e")))
dt=data.table(x=rbinom(5,2,0.5),y=rep(c("a","b","c","d","e")))
dt
```

```
##    x y
## 1: 2 a
## 2: 1 b
## 3: 1 c
## 4: 0 d
## 5: 0 e
```

```r
# subset of data.table
dt[2,] # dt where row is 2 and all of column
```

```
##    x y
## 1: 1 b
```

```r
dt[dt$y=="a",] # dt where row is where dt's y value equals to "a" and all of col
```

```
##    x y
## 1: 2 a
```

```r
dt[c(2,3)] # dt where row is 2 and 3 and all of col
```

```
##    x y
## 1: 1 b
## 2: 1 c
```

```r
dt[,c(2,3)] # subsetting col doesn't work the same as for dataframe
```

```
## [1] 2 3
```

```r
dt[,list(mean(x),sum(x))] # obtains a list of mean of x values of dt, and sum of x
```

```
##     V1 V2
## 1: 0.8  4
```

```r
dt[,table(y)] # ~table(dt$y); obtains a table of y values in dt
```

```
## y
## a b c d e 
## 1 1 1 1 1
```

```r
dt[,z:=x^2] # creates a new col z that is x ^ 2 
dt2<-dt # this does not actually create a new/separate copy
dt2[,y:=2]
```

```
## Warning in `[.data.table`(dt2, , `:=`(y, 2)): Coerced 'double' RHS to
## 'character' to match the column's type; may have truncated precision.
## Either change the target column to 'double' first (by creating a new
## 'double' vector length 5 (nrows of entire table) and assign that; i.e.
## 'replace' column), or coerce RHS to 'character' (e.g. 1L, NA_[real|
## integer]_, as.*, etc) to make your intent clear and for speed. Or, set the
## column type correctly up front when you create the table and stick to it,
## please.
```

```r
head(dt2)
```

```
##    x y z
## 1: 2 2 4
## 2: 1 2 1
## 3: 1 2 1
## 4: 0 2 0
## 5: 0 2 0
```

```r
head(dt) # dt2<-dt does not actually create a new copy
```

```
##    x y z
## 1: 2 2 4
## 2: 1 2 1
## 3: 1 2 1
## 4: 0 2 0
## 5: 0 2 0
```

```r
# multiple operations within creating a new col
dt[,m:={tmp<-(x+z);log2(tmp+5)}]
head(dt)
```

```
##    x y z        m
## 1: 2 2 4 3.459432
## 2: 1 2 1 2.807355
## 3: 1 2 1 2.807355
## 4: 0 2 0 2.321928
## 5: 0 2 0 2.321928
```

```r
# plyr like operations
dt[,a:=x>0]
head(dt)
```

```
##    x y z        m     a
## 1: 2 2 4 3.459432  TRUE
## 2: 1 2 1 2.807355  TRUE
## 3: 1 2 1 2.807355  TRUE
## 4: 0 2 0 2.321928 FALSE
## 5: 0 2 0 2.321928 FALSE
```

```r
# by a means where a condition is TRUE, it takes the mean of x and z
# and when a is false, collect those values and perform the func
dt[,b:=sum(x+z),by=a]
head(dt)
```

```
##    x y z        m     a  b
## 1: 2 2 4 3.459432  TRUE 10
## 2: 1 2 1 2.807355  TRUE 10
## 3: 1 2 1 2.807355  TRUE 10
## 4: 0 2 0 2.321928 FALSE  0
## 5: 0 2 0 2.321928 FALSE  0
```

```r
# special variables: .N
set.seed(123)
dt<-data.table(x=sample(letters[1:2],5,TRUE))
head(dt)
```

```
##    x
## 1: a
## 2: b
## 3: a
## 4: b
## 5: b
```

```r
dt[,.N,by=x] # .N counts by x
```

```
##    x N
## 1: a 2
## 2: b 3
```

```r
# special variables: Keys
dt<-data.table(x=rep(c("a","b","c"),each=3),y=rnorm(3))
setkey(dt,x) # set x as the key so that it can be extracted as below
dt
```

```
##    x         y
## 1: a -1.689556
## 2: a  1.239496
## 3: a -0.108966
## 4: b -1.689556
## 5: b  1.239496
## 6: b -0.108966
## 7: c -1.689556
## 8: c  1.239496
## 9: c -0.108966
```

```r
dt["a"]
```

```
##    x         y
## 1: a -1.689556
## 2: a  1.239496
## 3: a -0.108966
```

```r
dt1<-data.table(x=c("a","a","b","dt1"),y=1:4)
dt2<-data.table(x=c("a","b","dt2"),z=5:7)
setkey(dt1,x); setkey(dt2,x)
dt1
```

```
##      x y
## 1:   a 1
## 2:   a 2
## 3:   b 3
## 4: dt1 4
```

```r
dt2
```

```
##      x z
## 1:   a 5
## 2:   b 6
## 3: dt2 7
```

```r
# hard to interpret, but when x = a, y = 1 and 2 (dt1) and z = 5 (dt2), hence
# x=a;y=1;z=5
# x=a;y=2;z=5
# when x = b, y = 3 (dt1) and z = 6 hence
# x = b;y=3;z=6
# since there is no common x key value for dt1 and dt2 for dt1 and dt2, it is omitted
merge(dt1,dt2) 
```

```
##    x y z
## 1: a 1 5
## 2: a 2 5
## 3: b 3 6
```

```r
# fast reading
big_df<-data.frame(x=rnorm(1E6),y=rnorm(1E6))
file<-tempfile()
write.table(big_df,file=file,row.names=FALSE,col.names=TRUE,sep="\t",quote=FALSE)
if(!require(microbenchmark)){
  install.packages("microbenchmark",repo="https://cran.rstudio.com/")
}
library(microbenchmark)
#fast reading
microbenchmark(fread(file),times=1)
```

```
## Unit: milliseconds
##         expr      min       lq     mean   median       uq      max neval
##  fread(file) 503.2824 503.2824 503.2824 503.2824 503.2824 503.2824     1
```

```r
# normal read table
microbenchmark(read.table(file,header=TRUE,sep="\t"),times=1)
```

```
## Unit: seconds
##                                          expr      min       lq     mean
##  read.table(file, header = TRUE, sep = "\\t") 10.48997 10.48997 10.48997
##    median       uq      max neval
##  10.48997 10.48997 10.48997     1
```

###2) reading MySQL

```r
if(!require(RMySQL)){
  install.packages("RMySQL",repo="https://cran.rstudio.com/")
}
library(RMySQL)
# connect and obtain result
ucscDb<-dbConnect(MySQL(),user="genome",host="genome-mysql.cse.ucsc.edu")
result<-dbGetQuery(ucscDb,"show databases;"); dbDisconnect(ucscDb);
```

```
## [1] TRUE
```

```r
# connecting to hg19 db and listing all the tables
hg19<-dbConnect(MySQL(),user="genome",db="hg19",host="genome-mysql.cse.ucsc.edu")
allTables<-dbListTables(hg19)
length(allTables)
```

```
## [1] 11027
```

```r
allTables[1:5]
```

```
## [1] "HInv"         "HInvGeneMrna" "acembly"      "acemblyClass"
## [5] "acemblyPep"
```

```r
# get dimensions of specific table
dbListFields(hg19,"affyU133Plus2")
```

```
##  [1] "bin"         "matches"     "misMatches"  "repMatches"  "nCount"     
##  [6] "qNumInsert"  "qBaseInsert" "tNumInsert"  "tBaseInsert" "strand"     
## [11] "qName"       "qSize"       "qStart"      "qEnd"        "tName"      
## [16] "tSize"       "tStart"      "tEnd"        "blockCount"  "blockSizes" 
## [21] "qStarts"     "tStarts"
```

```r
dbGetQuery(hg19,"select count(*) from affyU133Plus2")
```

```
##   count(*)
## 1    58463
```

```r
# read from a table
affyData<-dbReadTable(hg19,"affyU133Plus2")
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 0 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 1 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 2 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 3 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 4 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 5 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 6 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 7 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 8 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 11
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 12
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 13
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 15
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 16
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 17
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 18
## imported as numeric
```

```r
str(affyData)
```

```
## 'data.frame':	58463 obs. of  22 variables:
##  $ bin        : num  585 585 585 585 585 585 585 585 73 585 ...
##  $ matches    : num  530 3355 4156 4667 5180 ...
##  $ misMatches : num  4 17 14 9 14 5 3 0 21 23 ...
##  $ repMatches : num  0 0 0 0 0 0 0 0 0 0 ...
##  $ nCount     : num  23 109 83 68 167 14 6 8 56 75 ...
##  $ qNumInsert : num  3 9 16 21 10 0 1 1 2 22 ...
##  $ qBaseInsert: num  41 67 18 42 38 0 1 1 2 41 ...
##  $ tNumInsert : num  3 9 2 3 1 0 1 2 1 3 ...
##  $ tBaseInsert: num  898 11621 93 5743 29 ...
##  $ strand     : chr  "-" "-" "-" "-" ...
##  $ qName      : chr  "225995_x_at" "225035_x_at" "226340_x_at" "1557034_s_at" ...
##  $ qSize      : num  637 3635 4318 4834 5399 ...
##  $ qStart     : num  5 0 3 48 0 0 0 1 12 3 ...
##  $ qEnd       : num  603 3548 4274 4834 5399 ...
##  $ tName      : chr  "chr1" "chr1" "chr1" "chr1" ...
##  $ tSize      : num  2.49e+08 2.49e+08 2.49e+08 2.49e+08 2.49e+08 ...
##  $ tStart     : num  14361 14381 14399 14406 19688 ...
##  $ tEnd       : num  15816 29483 18745 24893 25078 ...
##  $ blockCount : num  5 17 18 23 11 1 3 4 4 24 ...
##  $ blockSizes : chr  "93,144,229,70,21," "73,375,71,165,303,360,198,661,201,1,260,250,74,73,98,155,163," "690,10,32,33,376,4,5,15,5,11,7,41,277,859,141,51,443,1253," "99,352,286,24,49,14,6,5,8,149,14,44,98,12,10,355,837,59,8,1500,133,624,58," ...
##  $ qStarts    : chr  "34,132,278,541,611," "87,165,540,647,818,1123,1484,1682,2343,2545,2546,2808,3058,3133,3206,3317,3472," "44,735,746,779,813,1190,1195,1201,1217,1223,1235,1243,1285,1564,2423,2565,2617,3062," "0,99,452,739,764,814,829,836,842,851,1001,1016,1061,1160,1173,1184,1540,2381,2441,2450,3951,4103,4728," ...
##  $ tStarts    : chr  "14361,14454,14599,14968,15795," "14381,14454,14969,15075,15240,15543,15903,16104,16853,17054,17232,17492,17914,17988,18267,24736,29320," "14399,15089,15099,15131,15164,15540,15544,15549,15564,15569,15580,15587,15628,15906,16857,16998,17049,17492," "14406,20227,20579,20865,20889,20938,20952,20958,20963,20971,21120,21134,21178,21276,21288,21298,21653,22492,22551,22559,24059,2"| __truncated__ ...
```

```r
# select a specific subset
query<-dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 0 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 1 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 2 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 3 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 4 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 5 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 6 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 7 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 8 imported
## as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 11
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 12
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 13
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 15
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 16
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 17
## imported as numeric
```

```
## Warning in .local(conn, statement, ...): Unsigned INTEGER in col 18
## imported as numeric
```

```r
affyMis<-fetch(query); quantile(affyMis$misMatches)
```

```
##   0%  25%  50%  75% 100% 
##    1    1    2    2    3
```

```r
affyMisSmall<-fetch(query,n=10); dbClearResult(query);
```

```
## [1] TRUE
```

```r
dim(affyMisSmall)
```

```
## [1] 10 22
```

```r
dbDisconnect(hg19)
```

```
## [1] TRUE
```

###3) reading HDF5

```r
# heirarchical data format
# groups contain zero or more data sets/metadata
#       group header with grou name and list of attributes
#       group symbol table with list of objects in group
# datasets multidimensional array of data elements with metadata
#       have header with name,datatype,dataspace,storage layout
#       have data array with data
#  http:/www.hdfgroup.org

if(!file.exists("/data/biocLite.R")){
    fileUrl<-"http://bioconductor.org/biocLite.R"
    download.file(fileUrl,"./data/biocLite.R",method="curl")
}
source("http://bioconductor.org/biocLite.R")
```

```
## Bioconductor version 3.2 (BiocInstaller 1.20.1), ?biocLite for help
```

```r
if(!require(rhdf5)){
  biocLite("rhdf5")
}
library(rhdf5)
if(file.exists("example.h5")){
    file.remove("example.h5")
}
```

```
## [1] TRUE
```

```r
created<-h5createFile("example.h5")
created
```

```
## [1] TRUE
```

```r
# create groups
created<-h5createGroup("example.h5","foo")
created<-h5createGroup("example.h5","baa")
created<-h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
```

```
##   group   name     otype dclass dim
## 0     /    baa H5I_GROUP           
## 1     /    foo H5I_GROUP           
## 2  /foo foobaa H5I_GROUP
```

```r
# write to groups
A<-matrix(1:10,nr=5,nc=2)
h5write(A,"example.h5","foo/A")
B<-array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B,"scale")<-"liter"
h5write(B,"example.h5","foo/foobaa/B")
h5ls("example.h5")
```

```
##         group   name       otype  dclass       dim
## 0           /    baa   H5I_GROUP                  
## 1           /    foo   H5I_GROUP                  
## 2        /foo      A H5I_DATASET INTEGER     5 x 2
## 3        /foo foobaa   H5I_GROUP                  
## 4 /foo/foobaa      B H5I_DATASET   FLOAT 5 x 2 x 2
```

```r
# reading data
readA<-h5read("example.h5","foo/A")
readA
```

```
##      [,1] [,2]
## [1,]    1    6
## [2,]    2    7
## [3,]    3    8
## [4,]    4    9
## [5,]    5   10
```

```r
readA<-h5read("example.h5","foo/foobaa/B")
readA
```

```
## , , 1
## 
##      [,1] [,2]
## [1,]  0.1  0.6
## [2,]  0.2  0.7
## [3,]  0.3  0.8
## [4,]  0.4  0.9
## [5,]  0.5  1.0
## 
## , , 2
## 
##      [,1] [,2]
## [1,]  1.1  1.6
## [2,]  1.2  1.7
## [3,]  1.3  1.8
## [4,]  1.4  1.9
## [5,]  1.5  2.0
```

```r
# writing and reading chunks
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1)) # write 12,13,14 into rows 1 through 3 column 1 of foo/A within example.h5
h5read("example.h5","foo/A")
```

```
##      [,1] [,2]
## [1,]   12    6
## [2,]   13    7
## [3,]   14    8
## [4,]    4    9
## [5,]    5   10
```

###4) reading from the web

```r
# just in case google blocks the ip for accessing too often
if(!file.exists("data/google-scholar.html")){
    fileUrl<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
    download.file(fileUrl,"./data/google-scholar.html",method="curl")
}
htmlurl<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
con = url(htmlurl)
htmlCode<-readLines(con)
```

```
## Warning in readLines(con): incomplete final line found on 'http://
## scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en'
```

```r
close(con)

# parsing with XML
library(XML)
html<-htmlTreeParse(htmlurl,useInternalNodes=TRUE)
xpathSApply(html,"//title",xmlValue)
```

```
## [1] "Jeff Leek - Google Scholar Citations"
```

```r
# GET from httr package
if(!require(httr)){
  install.packages("httr",repo="https://cran.rstudio.com/")
}
library(httr)
html2=GET(htmlurl)
content2<-content(html2,as="text")
parsedHtml<-htmlParse(content2,asText=TRUE)
xpathSApply(parsedHtml,"//title",xmlValue)
```

```
## [1] "Jeff Leek - Google Scholar Citations"
```

```r
# accessing websites with password
pg1<-GET("http://httpbin.org/basic-auth/user/passwd") # denied due to authentication block
pg1
```

```
## Response [http://httpbin.org/basic-auth/user/passwd]
##   Date: 2016-03-11 00:32
##   Status: 401
##   Content-Type: <unknown>
## <EMPTY BODY>
```

```r
pg2<-GET("http://httpbin.org/basic-auth/user/passwd",authenticate("user","passwd")) # authenticated
pg2
```

```
## Response [http://httpbin.org/basic-auth/user/passwd]
##   Date: 2016-03-11 00:32
##   Status: 200
##   Content-Type: application/json
##   Size: 47 B
```

```
## No encoding supplied: defaulting to UTF-8.
```

```
## {
##   "authenticated": true, 
##   "user": "user"
## }
```

```r
# using handles
google<-handle("http://www.google.com")
pg1<-GET(handle=google,path="/") # cookies will be authenticated / maintained
pg2<-GET(handle=google,path="search")
```

# *********************** problem with 5th module *************************** #
###5) reading from APIs
```{r}'''
library(httr)
if(!require(base64enc)){
  install.packages("base64enc",repo="https://cran.rstudio.com/")
}
library(base64enc)
source("hidden.R") # contains consumer key/secret
myapp<-oauth_app("twitter",key=oauth()$consumer_key,secret=oauth()$consumer_secret)
sig<-sign_oauth1.0(app=myapp,token=oauth()$token_key,token_secret = oauth()$token_secret)
homeTL<-GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
json1<-content(homeTL)
json2<-jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
```'''

# *************************************************************************** #

###6) reading from other sources

```r
### files
# file - connection to text file
# url - connection to url
# gzfile - connection to .gz file
# bzfile - connection to .bz2 file

### loads data from Minitab, S, SAS, SPSS, Stata, Systat
# read.arff (Weka)
# read.dta (Stata)
# read.mtp (minitab)
# read.octave (octave)
# read.spss (SPSS)
# read.xport (SAS)

### reading images
# jpeg package
# readbitmap package
# png package
# bioconductor package - EBImage

### reading GIS data
# rgdal package
# rgeos package
# raster package

### reading music data
# tuneR package
# seewave custom package?
```

###7) subsetting / scoring

```r
set.seed(13435)
x<-data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15)) 
x<-x[sample(1:5),]; # shuffle around rows 1 through 5
x$var2[c(1,3)]<-NA # mark 1st and 3rd row value of var2 as NA (after shuffling above)
x
```

```
##   var1 var2 var3
## 1    2   NA   15
## 4    1   10   11
## 2    3   NA   12
## 3    5    6   14
## 5    4    9   13
```

```r
x[,1] # subsets column 1
```

```
## [1] 2 1 3 5 4
```

```r
x[,"var3"] # subsets column that matches the name "var3" (3rd col)
```

```
## [1] 15 11 12 14 13
```

```r
x[1:2,"var2"] # subsets row 1,2 of column "var2"
```

```
## [1] NA 10
```

```r
x[(x$var1<=3 & x$var3 > 11),] # select rows that match the var1 value <= 3 and var3>11 (and all cols)
```

```
##   var1 var2 var3
## 1    2   NA   15
## 2    3   NA   12
```

```r
x[(x$var1<=3 | x$var3 > 15),] # select rows that match the var1 value <= 3 OR var3>11 (and all cols)
```

```
##   var1 var2 var3
## 1    2   NA   15
## 4    1   10   11
## 2    3   NA   12
```

```r
x[which(x$var2>8),] # subset of x where var2 value is greater than 8 (DEALS WITH MISSING VALUES)
```

```
##   var1 var2 var3
## 4    1   10   11
## 5    4    9   13
```

```r
sort(x$var1) # get var1 column and sort it
```

```
## [1] 1 2 3 4 5
```

```r
sort(x$var1,decreasing=TRUE) # same as above but descending
```

```
## [1] 5 4 3 2 1
```

```r
sort(x$var2,na.last=TRUE) # by default (or NA) removes NA, TRUE puts last, FALSE puts first
```

```
## [1]  6  9 10 NA NA
```

```r
x[order(x$var1),] # subset of x where it's ordered by var1 value
```

```
##   var1 var2 var3
## 4    1   10   11
## 1    2   NA   15
## 2    3   NA   12
## 5    4    9   13
## 3    5    6   14
```

```r
x[order(x$var1,x$var3),] # same as above, but ordered by var1 and then by var3 (if var1 has ties, var3 is the tiebreaker)
```

```
##   var1 var2 var3
## 4    1   10   11
## 1    2   NA   15
## 2    3   NA   12
## 5    4    9   13
## 3    5    6   14
```

```r
### PLYR ###
library(plyr)
arrange(x,var1) # same as above above, but simpler (and notice lack of "")
```

```
##   var1 var2 var3
## 1    1   10   11
## 2    2   NA   15
## 3    3   NA   12
## 4    4    9   13
## 5    5    6   14
```

```r
arrange(x,desc(var1)) # descending "x[order(x$var1,decreasing=TRUE),]"
```

```
##   var1 var2 var3
## 1    5    6   14
## 2    4    9   13
## 3    3   NA   12
## 4    2   NA   15
## 5    1   10   11
```

```r
#############

x$var4<-rnorm(5) # adds a new column to x as "var4" with rnorm(5) applied
x
```

```
##   var1 var2 var3       var4
## 1    2   NA   15  0.1875960
## 4    1   10   11  1.7869764
## 2    3   NA   12  0.4966936
## 3    5    6   14  0.0631830
## 5    4    9   13 -0.5361329
```

```r
x<-cbind(x,"var5"=rnorm(5)) # column bind also works
x
```

```
##   var1 var2 var3       var4        var5
## 1    2   NA   15  0.1875960  0.62578490
## 4    1   10   11  1.7869764 -2.45083750
## 2    3   NA   12  0.4966936  0.08909424
## 3    5    6   14  0.0631830  0.47838570
## 5    4    9   13 -0.5361329  1.00053336
```

###8) summarizing data

```r
if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("data/restaurants.csv")){
    fileUrl<-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
    download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
}
restData<-read.csv("./data/restaurants.csv")
head(restData,n=1)
```

```
##   name zipCode neighborhood councilDistrict policeDistrict
## 1  410   21206    Frankford               2   NORTHEASTERN
##                          Location.1
## 1 4509 BELAIR ROAD\nBaltimore, MD\n
```

```r
tail(restData,n=1)
```

```
##        name zipCode neighborhood councilDistrict policeDistrict
## 1327 ZORBAS   21224    Greektown               2   SOUTHEASTERN
##                             Location.1
## 1327 4710 EASTERN Ave\nBaltimore, MD\n
```

```r
summary(restData)
```

```
##                            name         zipCode             neighborhood
##  MCDONALD'S                  :   8   Min.   :-21226   Downtown    :128  
##  POPEYES FAMOUS FRIED CHICKEN:   7   1st Qu.: 21202   Fells Point : 91  
##  SUBWAY                      :   6   Median : 21218   Inner Harbor: 89  
##  KENTUCKY FRIED CHICKEN      :   5   Mean   : 21185   Canton      : 81  
##  BURGER KING                 :   4   3rd Qu.: 21226   Federal Hill: 42  
##  DUNKIN DONUTS               :   4   Max.   : 21287   Mount Vernon: 33  
##  (Other)                     :1293                    (Other)     :863  
##  councilDistrict       policeDistrict
##  Min.   : 1.000   SOUTHEASTERN:385   
##  1st Qu.: 2.000   CENTRAL     :288   
##  Median : 9.000   SOUTHERN    :213   
##  Mean   : 7.191   NORTHERN    :157   
##  3rd Qu.:11.000   NORTHEASTERN: 72   
##  Max.   :14.000   EASTERN     : 67   
##                   (Other)     :145   
##                           Location.1    
##  1101 RUSSELL ST\nBaltimore, MD\n:   9  
##  201 PRATT ST\nBaltimore, MD\n   :   8  
##  2400 BOSTON ST\nBaltimore, MD\n :   8  
##  300 LIGHT ST\nBaltimore, MD\n   :   5  
##  300 CHARLES ST\nBaltimore, MD\n :   4  
##  301 LIGHT ST\nBaltimore, MD\n   :   4  
##  (Other)                         :1289
```

```r
str(restData)
```

```
## 'data.frame':	1327 obs. of  6 variables:
##  $ name           : Factor w/ 1277 levels "#1 CHINESE KITCHEN",..: 9 3 992 1 2 4 5 6 7 8 ...
##  $ zipCode        : int  21206 21231 21224 21211 21223 21218 21205 21211 21205 21231 ...
##  $ neighborhood   : Factor w/ 173 levels "Abell","Arlington",..: 53 52 18 66 104 33 98 133 98 157 ...
##  $ councilDistrict: int  2 1 1 14 9 14 13 7 13 1 ...
##  $ policeDistrict : Factor w/ 9 levels "CENTRAL","EASTERN",..: 3 6 6 4 8 3 6 4 6 6 ...
##  $ Location.1     : Factor w/ 1210 levels "1 BIDDLE ST\nBaltimore, MD\n",..: 835 334 554 755 492 537 505 530 507 569 ...
```

```r
quantile(restData$councilDistrict,na.rm=TRUE)
```

```
##   0%  25%  50%  75% 100% 
##    1    2    9   11   14
```

```r
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9),na.rm=TRUE) # gets 50%, 75%, 90% quantile
```

```
## 50% 75% 90% 
##   9  11  12
```

```r
table(restData$zipCode,useNA="ifany") # useNA = "ifany" if there's any use NA, "no" is no, "always" always use it
```

```
## 
## -21226  21201  21202  21205  21206  21207  21208  21209  21210  21211 
##      1    136    201     27     30      4      1      8     23     41 
##  21212  21213  21214  21215  21216  21217  21218  21220  21222  21223 
##     28     31     17     54     10     32     69      1      7     56 
##  21224  21225  21226  21227  21229  21230  21231  21234  21237  21239 
##    199     19     18      4     13    156    127      7      1      3 
##  21251  21287 
##      2      1
```

```r
table(restData$councilDistrict,restData$zipCode) # use councilDistrict as row and column as zipCode
```

```
##     
##      -21226 21201 21202 21205 21206 21207 21208 21209 21210 21211 21212
##   1       0     0    37     0     0     0     0     0     0     0     0
##   2       0     0     0     3    27     0     0     0     0     0     0
##   3       0     0     0     0     0     0     0     0     0     0     0
##   4       0     0     0     0     0     0     0     0     0     0    27
##   5       0     0     0     0     0     3     0     6     0     0     0
##   6       0     0     0     0     0     0     0     1    19     0     0
##   7       0     0     0     0     0     0     0     1     0    27     0
##   8       0     0     0     0     0     1     0     0     0     0     0
##   9       0     1     0     0     0     0     0     0     0     0     0
##   10      1     0     1     0     0     0     0     0     0     0     0
##   11      0   115   139     0     0     0     1     0     0     0     1
##   12      0    20    24     4     0     0     0     0     0     0     0
##   13      0     0     0    20     3     0     0     0     0     0     0
##   14      0     0     0     0     0     0     0     0     4    14     0
##     
##      21213 21214 21215 21216 21217 21218 21220 21222 21223 21224 21225
##   1      2     0     0     0     0     0     0     7     0   140     1
##   2      0     0     0     0     0     0     0     0     0    54     0
##   3      2    17     0     0     0     3     0     0     0     0     0
##   4      0     0     0     0     0     0     0     0     0     0     0
##   5      0     0    31     0     0     0     0     0     0     0     0
##   6      0     0    15     1     0     0     0     0     0     0     0
##   7      0     0     6     7    15     6     0     0     0     0     0
##   8      0     0     0     0     0     0     0     0     2     0     0
##   9      0     0     0     2     8     0     0     0    53     0     0
##   10     0     0     0     0     0     0     1     0     0     0    18
##   11     0     0     0     0     9     0     0     0     1     0     0
##   12    13     0     0     0     0    26     0     0     0     0     0
##   13    13     0     1     0     0     0     0     0     0     5     0
##   14     1     0     1     0     0    34     0     0     0     0     0
##     
##      21226 21227 21229 21230 21231 21234 21237 21239 21251 21287
##   1      0     0     0     1   124     0     0     0     0     0
##   2      0     0     0     0     0     0     1     0     0     0
##   3      0     1     0     0     0     7     0     0     2     0
##   4      0     0     0     0     0     0     0     3     0     0
##   5      0     0     0     0     0     0     0     0     0     0
##   6      0     0     0     0     0     0     0     0     0     0
##   7      0     0     0     0     0     0     0     0     0     0
##   8      0     2    13     0     0     0     0     0     0     0
##   9      0     0     0    11     0     0     0     0     0     0
##   10    18     0     0   133     0     0     0     0     0     0
##   11     0     0     0    11     0     0     0     0     0     0
##   12     0     0     0     0     2     0     0     0     0     0
##   13     0     1     0     0     1     0     0     0     0     1
##   14     0     0     0     0     0     0     0     0     0     0
```

```r
# checking for missing values
sum(is.na(restData$councilDistrict)) # sum of counts of missing values in councilDistrict
```

```
## [1] 0
```

```r
any(is.na(restData$councilDistrict)) # is there any missing values in councilDistrict?
```

```
## [1] FALSE
```

```r
all(restData$councilDistrict>0) # all should be greater than 0
```

```
## [1] TRUE
```

```r
all(restData$zipCode>0) # there is at least one negative zip code (invalid) data
```

```
## [1] FALSE
```

```r
colSums(is.na(restData)) # sum of all of the column of restData that has na values
```

```
##            name         zipCode    neighborhood councilDistrict 
##               0               0               0               0 
##  policeDistrict      Location.1 
##               0               0
```

```r
all(colSums(is.na(restData))==0) # all of the column should have 0 value for is.na check
```

```
## [1] TRUE
```

```r
# tally a table of counts when the zipcode matches 21212
table(restData$zipCode %in% c("21212"))
```

```
## 
## FALSE  TRUE 
##  1299    28
```

```r
# opposite is not as useful (when 21212 matches the zipcode)
table(c("21212") %in% restData$zipCode)
```

```
## 
## TRUE 
##    1
```

```r
# also multiple matches work (match 21212 or 21213)
table(restData$zipCode %in% c("21212","21213"))
```

```
## 
## FALSE  TRUE 
##  1268    59
```

```r
# subsetting values with specific characteristics
head(restData[restData$zipCode %in% c("21212","21213"),],3)
```

```
##                 name zipCode              neighborhood councilDistrict
## 29 BAY ATLANTIC CLUB   21212                  Downtown              11
## 39       BERMUDA BAR   21213             Broadway East              12
## 92         ATWATER'S   21212 Chinquapin Park-Belvedere               4
##    policeDistrict                         Location.1
## 29        CENTRAL    206 REDWOOD ST\nBaltimore, MD\n
## 39        EASTERN    1801 NORTH AVE\nBaltimore, MD\n
## 92       NORTHERN 529 BELVEDERE AVE\nBaltimore, MD\n
```

```r
data(UCBAdmissions)
DF<-as.data.frame(UCBAdmissions)
head(DF)
```

```
##      Admit Gender Dept Freq
## 1 Admitted   Male    A  512
## 2 Rejected   Male    A  313
## 3 Admitted Female    A   89
## 4 Rejected Female    A   19
## 5 Admitted   Male    B  353
## 6 Rejected   Male    B  207
```

```r
# cross tabs; Freq is what actually is displayed; Broken down by Gender (row) and Admit (col) 
xt<-xtabs(Freq ~ Gender + Admit,data=DF)
xt
```

```
##         Admit
## Gender   Admitted Rejected
##   Male       1198     1493
##   Female      557     1278
```

```r
# cross tabs for a larger number of variables are hard to see
warpbreaks$replicate<-rep(1:9,len=54)
head(warpbreaks,3)
```

```
##   breaks wool tension replicate
## 1     26    A       L         1
## 2     30    A       L         2
## 3     54    A       L         3
```

```r
# break down breaks by all the variables "." within
xt<-xtabs(breaks~.,data=warpbreaks)
# flat tables;makes it easier to read many variables
# by summarizing/formatting the data in a much smaller and
# compact form
ftable(xt)
```

```
##              replicate  1  2  3  4  5  6  7  8  9
## wool tension                                     
## A    L                 26 30 54 25 70 52 51 26 67
##      M                 18 21 29 17 12 18 35 30 36
##      H                 36 21 24 18 10 43 28 15 26
## B    L                 27 14 29 19 29 31 41 20 44
##      M                 42 26 19 16 39 28 21 39 29
##      H                 20 21 24 17 13 15 15 16 28
```

```r
# size of a data set
fakeData<-rnorm(1e6)
print(object.size(fakeData),units="Mb")
```

```
## 7.6 Mb
```

###9) creating new variables

```r
### creating new variables along with transformation of data
### variables to do the following:
# 1) missingness indicators
# 2) "cutting up" quantitative variables
# 3) applying transforms

if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("data/restaurants.csv")){
    fileUrl<-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
    download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
}
restData<-read.csv("./data/restaurants.csv")

### review ############################
# creating sequences
# skipping by 2 from 1 to 10 (1,3,5,7,9)
s1<-seq(1,10,by=2); s1 
```

```
## [1] 1 3 5 7 9
```

```r
# from 1 to 10, make it fit the length 3 (1.0, 5.5, 10.0)
s2<-seq(1,10,length=3);s2
```

```
## [1]  1.0  5.5 10.0
```

```r
# counts along the given list
s3<-seq(along=c(1,3,8,25,100)); s3
```

```
## [1] 1 2 3 4 5
```

```r
# subsetting variables (after creating variable)
restData$nearMe<-restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
```

```
## 
## FALSE  TRUE 
##  1314    13
```

```r
#######################################

# creating binary variables
restData$zipWrong<-ifelse(restData$zipCode<0,TRUE,FALSE)
table(restData$zipWrong,restData$zipCode<0)
```

```
##        
##         FALSE TRUE
##   FALSE  1326    0
##   TRUE      0    1
```

```r
# creating categorical variables
restData$zipGroups<-cut(restData$zipCode,breaks<-quantile(restData$zipCode))
table(restData$zipGroups,restData$zipCode)
```

```
##                        
##                         -21226 21201 21202 21205 21206 21207 21208 21209
##   (-2.123e+04,2.12e+04]      0   136   201     0     0     0     0     0
##   (2.12e+04,2.122e+04]       0     0     0    27    30     4     1     8
##   (2.122e+04,2.123e+04]      0     0     0     0     0     0     0     0
##   (2.123e+04,2.129e+04]      0     0     0     0     0     0     0     0
##                        
##                         21210 21211 21212 21213 21214 21215 21216 21217
##   (-2.123e+04,2.12e+04]     0     0     0     0     0     0     0     0
##   (2.12e+04,2.122e+04]     23    41    28    31    17    54    10    32
##   (2.122e+04,2.123e+04]     0     0     0     0     0     0     0     0
##   (2.123e+04,2.129e+04]     0     0     0     0     0     0     0     0
##                        
##                         21218 21220 21222 21223 21224 21225 21226 21227
##   (-2.123e+04,2.12e+04]     0     0     0     0     0     0     0     0
##   (2.12e+04,2.122e+04]     69     0     0     0     0     0     0     0
##   (2.122e+04,2.123e+04]     0     1     7    56   199    19     0     0
##   (2.123e+04,2.129e+04]     0     0     0     0     0     0    18     4
##                        
##                         21229 21230 21231 21234 21237 21239 21251 21287
##   (-2.123e+04,2.12e+04]     0     0     0     0     0     0     0     0
##   (2.12e+04,2.122e+04]      0     0     0     0     0     0     0     0
##   (2.122e+04,2.123e+04]     0     0     0     0     0     0     0     0
##   (2.123e+04,2.129e+04]    13   156   127     7     1     3     2     1
```

```r
# easier cutting
if(!require(Hmisc)){
  install.packages("Hmisc",repo="https://cran.rstudio.com/")
}
library(Hmisc)
restData$zipGroups<-cut2(restData$zipCode,g=4)
table(restData$zipGroups)
```

```
## 
## [-21226,21205) [ 21205,21220) [ 21220,21227) [ 21227,21287] 
##            338            375            300            314
```

```r
# creating factor variables
restData$zcf<-factor(restData$zipCode)
restData$zcf[1:10]
```

```
##  [1] 21206 21231 21224 21211 21223 21218 21205 21211 21205 21231
## 32 Levels: -21226 21201 21202 21205 21206 21207 21208 21209 ... 21287
```

```r
class(restData$zcf)
```

```
## [1] "factor"
```

```r
# levels of factor variables
yesno<-sample(c("yes","no"),size=10,replace=TRUE)
# by default, levels value-wise (alphanumeric value)
yesnofac<-factor(yesno,levels=c("yes","no"))
# can manually re-level based on reference value
relevel(yesnofac,ref="yes")
```

```
##  [1] yes no  no  yes no  yes no  no  yes yes
## Levels: yes no
```

```r
# Hmisc cutting produces factor variables
restData$zipGroups<-cut2(restData$zipCode,g=4)
table(restData$zipGroups)
```

```
## 
## [-21226,21205) [ 21205,21220) [ 21220,21227) [ 21227,21287] 
##            338            375            300            314
```

```r
# using mutate function (Hmisc & plyr) to create new version of the variable 
# and simultaneously added to a data set

if(!require(plyr)){
  install.packages("plyr",repo="https://cran.rstudio.com/")
}
library(plyr)
# mutate old dataframe by adding a new variable "zipGroups" that equals to the function of the original rest data frame
restData2<-mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
```

```
## 
## [-21226,21205) [ 21205,21220) [ 21220,21227) [ 21227,21287] 
##            338            375            300            314
```

```r
# mutate adds "function" such as ...
#   abs(x)            absolute
#   sqrt(x)           square root
#   ceiling(x)        ceiling
#   floor(x)          floor
#   round(x,digits=n) rounding to digits
#   signif(x,digits=n)rounding to sig fig
#   cos(x),sin(x)     cosine, sine
#   log(x), log2(x)   natural log, log base 2, et cetera
#   exp(x)            exponential of x
```

###10) reshaping data

```r
# each variable forms a column
# each observation forms a row
# each table/file stores data regarding one KIND of observation

if(!require(reshape2)){
  install.packages("reshape2",repos = "https://cran.rstudio.com/")
}
library(reshape2)
head(mtcars,n=3)
```

```
##                mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
```

```r
# melting data frames
mtcars$carname<-rownames(mtcars)
# differentiation of id variables and measure variables
carMelt<-melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
head(carMelt,n=3) # show mpg variables 
```

```
##         carname gear cyl variable value
## 1     Mazda RX4    4   6      mpg  21.0
## 2 Mazda RX4 Wag    4   6      mpg  21.0
## 3    Datsun 710    4   4      mpg  22.8
```

```r
tail(carMelt,n=3) # shows hp variables
```

```
##          carname gear cyl variable value
## 62  Ferrari Dino    5   6       hp   175
## 63 Maserati Bora    5   8       hp   335
## 64    Volvo 142E    4   4       hp   109
```

```r
# recasting data frames
# left hand is cyl and the variable is set as "mpg" and "hp" previously in melt function above
# without any functions, it aggregates the data set, so 11 in mpg and 11 in hp means 11 measures of mpg and hp
cylData<-dcast(carMelt,cyl~variable);cylData
```

```
## Aggregation function missing: defaulting to length
```

```
##   cyl mpg hp
## 1   4  11 11
## 2   6   7  7
## 3   8  14 14
```

```r
# by providing the function, it gets / applies the function 'mean' on to each variables
cylData2<-dcast(carMelt,cyl~variable,mean);cylData2
```

```
##   cyl      mpg        hp
## 1   4 26.66364  82.63636
## 2   6 19.74286 122.28571
## 3   8 15.10000 209.21429
```

```r
# averaging values
# spray values range from A through F
head(InsectSprays)
```

```
##   count spray
## 1    10     A
## 2     7     A
## 3    20     A
## 4    14     A
## 5    14     A
## 6    12     A
```

```r
# sums the spray counts
tapply(X=InsectSprays$count,INDEX=InsectSprays$spray,FUN=sum)
```

```
##   A   B   C   D   E   F 
## 174 184  25  59  42 200
```

```r
# another way - split
spIns<-split(x=InsectSprays$count,f=InsectSprays$spray); spIns
```

```
## $A
##  [1] 10  7 20 14 14 12 10 23 17 20 14 13
## 
## $B
##  [1] 11 17 21 11 16 14 17 17 19 21  7 13
## 
## $C
##  [1] 0 1 7 2 3 1 2 1 3 0 1 4
## 
## $D
##  [1]  3  5 12  6  4  3  5  5  5  5  2  4
## 
## $E
##  [1] 3 5 3 5 3 6 1 1 3 2 6 4
## 
## $F
##  [1] 11  9 15 22 15 16 13 10 26 26 24 13
```

```r
# another way - apply
sprCount<-lapply(X=spIns,FUN=sum); sprCount
```

```
## $A
## [1] 174
## 
## $B
## [1] 184
## 
## $C
## [1] 25
## 
## $D
## [1] 59
## 
## $E
## [1] 42
## 
## $F
## [1] 200
```

```r
# another way - combine
unlist(x=sprCount)
```

```
##   A   B   C   D   E   F 
## 174 184  25  59  42 200
```

```r
sapply(X=spIns,FUN=sum)
```

```
##   A   B   C   D   E   F 
## 174 184  25  59  42 200
```

```r
# another way - plyr package
if(!require(plyr)){
  install.packages("plyr",repos = "https://cran.rstudio.com/")
}
library(plyr)
# does not work for some reason on knitr; works on R console
#ddply(InsectSprays,.(spray),summarize,sum=sum(count))

# creating a new variable
# same error as above
#spraySums<-ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum))
#dim(spraySums)
```

###11) managing data frames with dplyr - using the tools

```r
if(!require(dplyr)){
  install.packages("dplyr",repos = "https://cran.rstudio.com/")
}
library(dplyr)

options(width=105)

if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("data/chicago.rds")){
    fileUrl<-"https://github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/dplyr/chicago.rds?raw=true"
    download.file(fileUrl,destfile="./data/chicago.rds",mode="wb")
}
chicago<-readRDS("./data/chicago.rds")
# selects from "city" column to "dptp" column
head(select(chicago,city:dptp))
```

```
##   city tmpd   dptp
## 1 chic 31.5 31.500
## 2 chic 33.0 29.875
## 3 chic 33.0 27.375
## 4 chic 29.0 28.625
## 5 chic 32.0 28.875
## 6 chic 40.0 35.125
```

```r
# select everything BUT the city column to dptp column
head(select(chicago,-(city:dptp)))
```

```
##         date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
## 1 1987-01-01         NA   34.00000 4.250000  19.98810
## 2 1987-01-02         NA         NA 3.304348  23.19099
## 3 1987-01-03         NA   34.16667 3.333333  23.81548
## 4 1987-01-04         NA   47.00000 4.375000  30.43452
## 5 1987-01-05         NA         NA 4.750000  30.33333
## 6 1987-01-06         NA   48.00000 5.833333  25.77233
```

```r
i<-match("city",names(chicago)); i
```

```
## [1] 1
```

```r
j<-match("dptp",names(chicago)); j
```

```
## [1] 3
```

```r
# to do the same thing with default R functions...
head(chicago[,-(i:j)])
```

```
##         date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
## 1 1987-01-01         NA   34.00000 4.250000  19.98810
## 2 1987-01-02         NA         NA 3.304348  23.19099
## 3 1987-01-03         NA   34.16667 3.333333  23.81548
## 4 1987-01-04         NA   47.00000 4.375000  30.43452
## 5 1987-01-05         NA         NA 4.750000  30.33333
## 6 1987-01-06         NA   48.00000 5.833333  25.77233
```

```r
# filter out pm25tmean2 value that's greater than 30)
chic.f<-filter(chicago,pm25tmean2>30); head(chic.f,3)
```

```
##   city tmpd dptp       date pm25tmean2 pm10tmean2  o3tmean2 no2tmean2
## 1 chic   23 21.9 1998-01-17      38.10   32.46154  3.180556   25.3000
## 2 chic   28 25.8 1998-01-23      33.95   38.69231  1.750000   29.3763
## 3 chic   55 51.3 1998-04-30      39.40   34.00000 10.786232   25.3131
```

```r
# can filter multiple logical statements
chic.f2<-filter(chicago,pm25tmean2>30 & tmpd>80); head(chic.f2,3)
```

```
##   city tmpd dptp       date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
## 1 chic   81 71.2 1998-08-23       39.6       59.0 45.86364  14.32639
## 2 chic   81 70.4 1998-09-06       31.5       50.5 50.66250  20.31250
## 3 chic   82 72.2 2001-07-20       32.3       58.5 33.00380  33.67500
```

```r
# arrange by date (default: ascending)
chicago<-arrange(chicago, date); head(chicago,3)
```

```
##   city tmpd   dptp       date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
## 1 chic 31.5 31.500 1987-01-01         NA   34.00000 4.250000  19.98810
## 2 chic 33.0 29.875 1987-01-02         NA         NA 3.304348  23.19099
## 3 chic 33.0 27.375 1987-01-03         NA   34.16667 3.333333  23.81548
```

```r
chicago<-arrange(chicago, desc(date)); head(chicago,3)
```

```
##   city tmpd dptp       date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
## 1 chic   35 30.1 2005-12-31   15.00000       23.5 2.531250  13.25000
## 2 chic   36 31.0 2005-12-30   15.05714       19.2 3.034420  22.80556
## 3 chic   35 29.4 2005-12-29    7.45000       23.5 6.794837  19.97222
```

```r
# renaming column (variable); which is annoying to do with vanilla package(s)
# new = old
chicago<-rename(chicago, pm25=pm25tmean2, dewpoint=dptp); head(chicago,3)
```

```
##   city tmpd dewpoint       date     pm25 pm10tmean2 o3tmean2 no2tmean2
## 1 chic   35     30.1 2005-12-31 15.00000       23.5 2.531250  13.25000
## 2 chic   36     31.0 2005-12-30 15.05714       19.2 3.034420  22.80556
## 3 chic   35     29.4 2005-12-29  7.45000       23.5 6.794837  19.97222
```

```r
# mutate; transform existing variable or create a new variable
chicago<-mutate(chicago, pm25detrend=pm25-mean(pm25,na.rm=TRUE)); head(select(chicago,pm25,pm25detrend))
```

```
##       pm25 pm25detrend
## 1 15.00000   -1.230958
## 2 15.05714   -1.173815
## 3  7.45000   -8.780958
## 4 17.75000    1.519042
## 5 23.56000    7.329042
## 6  8.40000   -7.830958
```

```r
# group_by; first mutated to include a factor (>80 = hot, <=80 = cold)
chicago<-mutate(chicago, tempcat=factor(1*(tmpd>80),labels=c("cold","hot")))
head(chicago,3);tail(chicago,3)
```

```
##   city tmpd dewpoint       date     pm25 pm10tmean2 o3tmean2 no2tmean2 pm25detrend tempcat
## 1 chic   35     30.1 2005-12-31 15.00000       23.5 2.531250  13.25000   -1.230958    cold
## 2 chic   36     31.0 2005-12-30 15.05714       19.2 3.034420  22.80556   -1.173815    cold
## 3 chic   35     29.4 2005-12-29  7.45000       23.5 6.794837  19.97222   -8.780958    cold
```

```
##      city tmpd dewpoint       date pm25 pm10tmean2 o3tmean2 no2tmean2 pm25detrend tempcat
## 6938 chic 33.0   27.375 1987-01-03   NA   34.16667 3.333333  23.81548          NA    cold
## 6939 chic 33.0   29.875 1987-01-02   NA         NA 3.304348  23.19099          NA    cold
## 6940 chic 31.5   31.500 1987-01-01   NA   34.00000 4.250000  19.98810          NA    cold
```

```r
hotcold<-group_by(chicago,tempcat);hotcold
```

```
## Source: local data frame [6,940 x 10]
## Groups: tempcat [3]
## 
##     city  tmpd dewpoint       date     pm25 pm10tmean2  o3tmean2 no2tmean2 pm25detrend tempcat
##    (chr) (dbl)    (dbl)     (date)    (dbl)      (dbl)     (dbl)     (dbl)       (dbl)  (fctr)
## 1   chic    35     30.1 2005-12-31 15.00000       23.5  2.531250  13.25000   -1.230958    cold
## 2   chic    36     31.0 2005-12-30 15.05714       19.2  3.034420  22.80556   -1.173815    cold
## 3   chic    35     29.4 2005-12-29  7.45000       23.5  6.794837  19.97222   -8.780958    cold
## 4   chic    37     34.5 2005-12-28 17.75000       27.5  3.260417  19.28563    1.519042    cold
## 5   chic    40     33.6 2005-12-27 23.56000       27.0  4.468750  23.50000    7.329042    cold
## 6   chic    35     29.6 2005-12-26  8.40000        8.5 14.041667  16.81944   -7.830958    cold
## 7   chic    35     32.1 2005-12-25  6.70000        8.0 14.354167  13.79167   -9.530958    cold
## 8   chic    37     35.2 2005-12-24 30.77143       25.2  1.770833  31.98611   14.540471    cold
## 9   chic    41     32.6 2005-12-23 32.90000       34.5  6.906250  29.08333   16.669042    cold
## 10  chic    22     23.3 2005-12-22 36.65000       42.5  5.385417  33.73026   20.419042    cold
## ..   ...   ...      ...        ...      ...        ...       ...       ...         ...     ...
```

```r
# average of pm25, maximum value of o3 mean, median of no2 mean
summarize(hotcold,pm25=mean(pm25),o3=max(o3tmean2),no2=median(no2tmean2))
```

```
## Source: local data frame [3 x 4]
## 
##   tempcat    pm25        o3      no2
##    (fctr)   (dbl)     (dbl)    (dbl)
## 1    cold      NA 66.587500 24.54924
## 2     hot      NA 62.969656 24.93870
## 3      NA 47.7375  9.416667 37.44444
```

```r
# fix na values for mean
summarize(hotcold,pm25=mean(pm25,na.rm=TRUE),o3=max(o3tmean2),no2=median(no2tmean2))
```

```
## Source: local data frame [3 x 4]
## 
##   tempcat     pm25        o3      no2
##    (fctr)    (dbl)     (dbl)    (dbl)
## 1    cold 15.97807 66.587500 24.54924
## 2     hot 26.48118 62.969656 24.93870
## 3      NA 47.73750  9.416667 37.44444
```

```r
# ********************************************************************************************* #
# another usage of mutate & group_by;
# for some reason on knitr the following is broken. (dplyr function error); works on console
#chicago<-mutate(chicago,year=as.POSIXlt(date)$year+1900)
#years<-group_by(chicago,year)
# yields the following: 
# Source: local data frame [19 x 4]

#    year     pm25       o3      no2
#   (dbl)    (dbl)    (dbl)    (dbl)
#1   1987      NaN 62.96966 23.49369
#2   1988      NaN 61.67708 24.52296
#3   1989      NaN 59.72727 26.14062
#summarize(years,pm25=mean(pm25,na.rm=TRUE),o3=max(o3tmean2),no2=median(no2tmean2))
# ********************************************************************************************* #

# dplyr pipeline operator:
# take the chicago, pipeline into mutate function, create a new variable "month"
# and then take the output of "mutate", group_by the "month",
# and then take the output of group_by and then run it through summarize
chicago %>% mutate(month=as.POSIXlt(date)$mon + 1) %>% group_by(month) %>% summarize(pm25=mean(pm25,na.rm=TRUE),o3=max(o3tmean2),no2=median(no2tmean2))
```

```
## Source: local data frame [12 x 4]
## 
##    month     pm25       o3      no2
##    (dbl)    (dbl)    (dbl)    (dbl)
## 1      1 17.76996 28.22222 25.35417
## 2      2 20.37513 37.37500 26.78034
## 3      3 17.40818 39.05000 26.76984
## 4      4 13.85879 47.94907 25.03125
## 5      5 14.07420 52.75000 24.22222
## 6      6 15.86461 66.58750 25.01140
## 7      7 16.57087 59.54167 22.38442
## 8      8 16.93380 53.96701 22.98333
## 9      9 15.91279 57.48864 24.47917
## 10    10 14.23557 47.09275 24.15217
## 11    11 15.15794 29.45833 23.56537
## 12    12 17.52221 27.70833 24.45773
```

```r
# very useful!
```

###12) merging data

```r
# downloading necessary files #
if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("./data/reviews.csv")){
  fileUrl1="https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
  download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
}
if(!file.exists("./data/solutions.csv")){
  fileUrl2="https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
  download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
}

reviews=read.csv("./data/reviews.csv"); solutions<-read.csv("./data/solutions.csv")

# checking the data are there
head(reviews,3)
```

```
##   id solution_id reviewer_id      start       stop time_left accept
## 1  1           3          27 1304095698 1304095758      1754      1
## 2  2           4          22 1304095188 1304095206      2306      1
## 3  3           5          28 1304095276 1304095320      2192      1
```

```r
head(solutions,3)
```

```
##   id problem_id subject_id      start       stop time_left answer
## 1  1        156         29 1304095119 1304095169      2343      B
## 2  2        269         25 1304095119 1304095183      2329      C
## 3  3         34         22 1304095127 1304095146      2366      C
```

```r
# merging data - merge()
# import parameters: x, y, by, by.x, by.y, all
names(reviews); names(solutions)
```

```
## [1] "id"          "solution_id" "reviewer_id" "start"       "stop"       
## [6] "time_left"   "accept"
```

```
## [1] "id"         "problem_id" "subject_id" "start"      "stop"      
## [6] "time_left"  "answer"
```

```r
# merges 'reviews' & 'solutions'
mergedData<-merge(reviews,solutions,by.x="solution_id",by.y="id",all=TRUE)
head(mergedData,3)
```

```
##   solution_id id reviewer_id    start.x     stop.x time_left.x accept
## 1           1  4          26 1304095267 1304095423        2089      1
## 2           2  6          29 1304095471 1304095513        1999      1
## 3           3  1          27 1304095698 1304095758        1754      1
##   problem_id subject_id    start.y     stop.y time_left.y answer
## 1        156         29 1304095119 1304095169        2343      B
## 2        269         25 1304095119 1304095183        2329      C
## 3         34         22 1304095127 1304095146        2366      C
```

```r
# default - merge all common column names
# intersect shows all intersecting column names (default pkg)
intersect(names(solutions),names(reviews))
```

```
## [1] "id"        "start"     "stop"      "time_left"
```

```r
# merging all common column names 
mergedData2<-merge(reviews,solutions,all=TRUE)
head(mergedData2)
```

```
##   id      start       stop time_left solution_id reviewer_id accept
## 1  1 1304095119 1304095169      2343          NA          NA     NA
## 2  1 1304095698 1304095758      1754           3          27      1
## 3  2 1304095119 1304095183      2329          NA          NA     NA
## 4  2 1304095188 1304095206      2306           4          22      1
## 5  3 1304095127 1304095146      2366          NA          NA     NA
## 6  3 1304095276 1304095320      2192           5          28      1
##   problem_id subject_id answer
## 1        156         29      B
## 2         NA         NA   <NA>
## 3        269         25      C
## 4         NA         NA   <NA>
## 5         34         22      C
## 6         NA         NA   <NA>
```

```r
# using "join" in the "plyr" package
df1<-data.frame(id=sample(1:10),x=rnorm(10))
df2<-data.frame(id=sample(1:10),y=rnorm(10))
arrange(join(df1,df2),id)
```

```
## Joining by: id
```

```
##    id           x          y
## 1   1  1.80724280 -1.0356159
## 2   2 -1.28531483  0.5351612
## 3   3 -0.32160219 -0.1693730
## 4   4 -0.45027787  1.8427056
## 5   5 -0.01943862  2.0314284
## 6   6  0.24730847 -2.3127374
## 7   7  0.77304686  0.7990271
## 8   8 -1.34462418  1.0341373
## 9   9 -0.19787792 -1.0193167
## 10 10 -0.72433867  0.8355025
```

```r
# if you have multiple data frames; join_all()
# this facilitates a function that is challenging (relatively) with merge()
df3<-data.frame(id=sample(1:10),z=rnorm(10))
dfList<-list(df1,df2,df3);dfList
```

```
## [[1]]
##    id           x
## 1   9 -0.19787792
## 2   6  0.24730847
## 3   1  1.80724280
## 4   7  0.77304686
## 5   2 -1.28531483
## 6   5 -0.01943862
## 7   4 -0.45027787
## 8  10 -0.72433867
## 9   3 -0.32160219
## 10  8 -1.34462418
## 
## [[2]]
##    id          y
## 1   2  0.5351612
## 2  10  0.8355025
## 3   4  1.8427056
## 4   6 -2.3127374
## 5   9 -1.0193167
## 6   5  2.0314284
## 7   7  0.7990271
## 8   8  1.0341373
## 9   3 -0.1693730
## 10  1 -1.0356159
## 
## [[3]]
##    id          z
## 1   7 -1.0364760
## 2   4 -0.6773836
## 3   9  1.4272538
## 4   3  1.2990209
## 5   1 -0.7264671
## 6   8  0.8832502
## 7   6  0.8278714
## 8   2 -0.1262739
## 9   5 -1.9793637
## 10 10 -0.9609792
```

```r
arrange(join_all(dfList),id)
```

```
## Joining by: id
## Joining by: id
```

```
##    id           x          y          z
## 1   1  1.80724280 -1.0356159 -0.7264671
## 2   2 -1.28531483  0.5351612 -0.1262739
## 3   3 -0.32160219 -0.1693730  1.2990209
## 4   4 -0.45027787  1.8427056 -0.6773836
## 5   5 -0.01943862  2.0314284 -1.9793637
## 6   6  0.24730847 -2.3127374  0.8278714
## 7   7  0.77304686  0.7990271 -1.0364760
## 8   8 -1.34462418  1.0341373  0.8832502
## 9   9 -0.19787792 -1.0193167  1.4272538
## 10 10 -0.72433867  0.8355025 -0.9609792
```

###13) editing text variables

```r
# loading necessary data
if(!file.exists("./data")){ dir.create("./data") }
if(!file.exists("./data/cameras.csv")){
  fileUrl<-"https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
  download.file(fileUrl,destfile="./data/cameras.csv",method="curl")
}
cameraData<-read.csv("./data/cameras.csv")

# toupper() & tolower() to fix character vectors
names(cameraData)
```

```
## [1] "address"      "direction"    "street"       "crossStreet" 
## [5] "intersection" "Location.1"
```

```r
toupper(names(cameraData))
```

```
## [1] "ADDRESS"      "DIRECTION"    "STREET"       "CROSSSTREET" 
## [5] "INTERSECTION" "LOCATION.1"
```

```r
tolower(names(cameraData))
```

```
## [1] "address"      "direction"    "street"       "crossstreet" 
## [5] "intersection" "location.1"
```

```r
# splitting character vectors - strsplit()
# this splits by period "."
# escape characters necessary since "." is a reserved character
splitNames<-strsplit(names(cameraData),"\\.");splitNames
```

```
## [[1]]
## [1] "address"
## 
## [[2]]
## [1] "direction"
## 
## [[3]]
## [1] "street"
## 
## [[4]]
## [1] "crossStreet"
## 
## [[5]]
## [1] "intersection"
## 
## [[6]]
## [1] "Location" "1"
```

```r
# quick aside - lists
mylist<-list(letters=c("A","b","c"),numbers=1:3,matrix(1:25,ncol=5));mylist
```

```
## $letters
## [1] "A" "b" "c"
## 
## $numbers
## [1] 1 2 3
## 
## [[3]]
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    6   11   16   21
## [2,]    2    7   12   17   22
## [3,]    3    8   13   18   23
## [4,]    4    9   14   19   24
## [5,]    5   10   15   20   25
```

```r
mylist[1]
```

```
## $letters
## [1] "A" "b" "c"
```

```r
mylist$letters
```

```
## [1] "A" "b" "c"
```

```r
mylist[[1]]
```

```
## [1] "A" "b" "c"
```

```r
# fixing character vectors via sapply()
# to remove the period characters ("Location.1" --> "Location" "1")
splitNames[[6]][1]
```

```
## [1] "Location"
```

```r
splitNames
```

```
## [[1]]
## [1] "address"
## 
## [[2]]
## [1] "direction"
## 
## [[3]]
## [1] "street"
## 
## [[4]]
## [1] "crossStreet"
## 
## [[5]]
## [1] "intersection"
## 
## [[6]]
## [1] "Location" "1"
```

```r
# this only collects / returns the first element if there are multiple elements
firstElement<-function(x){x[1]}
sapply(splitNames,firstElement)
```

```
## [1] "address"      "direction"    "street"       "crossStreet" 
## [5] "intersection" "Location"
```

```r
# downloading necessary files again... and loading
if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("./data/reviews.csv")){
  fileUrl1="https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
  download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
}
if(!file.exists("./data/solutions.csv")){
  fileUrl2="https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
  download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
}
reviews<-read.csv("./data/reviews.csv");solutions<-read.csv("./data/solutions.csv")
head(reviews,2);head(solutions,2)
```

```
##   id solution_id reviewer_id      start       stop time_left accept
## 1  1           3          27 1304095698 1304095758      1754      1
## 2  2           4          22 1304095188 1304095206      2306      1
```

```
##   id problem_id subject_id      start       stop time_left answer
## 1  1        156         29 1304095119 1304095169      2343      B
## 2  2        269         25 1304095119 1304095183      2329      C
```

```r
# fixing character vectors - sub()
# substituting out character (replace "_" with "")
names(reviews)
```

```
## [1] "id"          "solution_id" "reviewer_id" "start"       "stop"       
## [6] "time_left"   "accept"
```

```r
sub("_","",names(reviews))
```

```
## [1] "id"         "solutionid" "reviewerid" "start"      "stop"      
## [6] "timeleft"   "accept"
```

```r
# fixing character vectors - gsub()
# gsub replaces multiple instances (not just the first ocurrence)
testName<-"this_is_a_test"
sub("_","",testName)
```

```
## [1] "thisis_a_test"
```

```r
gsub("_","",testName)
```

```
## [1] "thisisatest"
```

```r
# finding values - grep(), grepl()
# look for "Alameda" in cameraData$intersection
# appears in the 4th, 5th, and 36th element of intersection variable
grep("Alameda",cameraData$intersection)
```

```
## [1]  4  5 36
```

```r
# grepl returns a vector that's true whenever Alameda appears, false otherwise
table(grepl("Alameda",cameraData$intersection))
```

```
## 
## FALSE  TRUE 
##    77     3
```

```r
# subsetting using grepl;
# successfully removes out when intersection variable is "Alameda"
cameraData2<-cameraData[!grepl("Alameda",cameraData$intersection),];head(cameraData2)
```

```
##                          address direction      street  crossStreet
## 1       S CATON AVE & BENSON AVE       N/B   Caton Ave   Benson Ave
## 2       S CATON AVE & BENSON AVE       S/B   Caton Ave   Benson Ave
## 3 WILKENS AVE & PINE HEIGHTS AVE       E/B Wilkens Ave Pine Heights
## 6        ERDMAN AVE & N MACON ST       E/B      Erdman     Macon St
## 7        ERDMAN AVE & N MACON ST       W/B      Erdman     Macon St
## 8      N CHARLES ST & E LAKE AVE       S/B     Charles     Lake Ave
##                 intersection                      Location.1
## 1     Caton Ave & Benson Ave (39.2693779962, -76.6688185297)
## 2     Caton Ave & Benson Ave (39.2693157898, -76.6689698176)
## 3 Wilkens Ave & Pine Heights  (39.2720252302, -76.676960806)
## 6         Erdman  & Macon St (39.3068045671, -76.5593167803)
## 7         Erdman  & Macon St  (39.306966535, -76.5593122365)
## 8         Charles & Lake Ave  (39.3690535299, -76.625826716)
```

```r
# more utilites of grep();
# value=TRUE gets the value instead of the index when GREP matches
grep("Alameda",cameraData$intersection,value=TRUE)
```

```
## [1] "The Alameda  & 33rd St"   "E 33rd  & The Alameda"   
## [3] "Harford \n & The Alameda"
```

```r
# looking for when the search query does not appear in a variable;
# "JeffStreet" is not found, hence outputs integer 0
grep("JeffStreet",cameraData$intersection)
```

```
## integer(0)
```

```r
# and such output is also length zero (which makes it easier to search for)
length(grep("JeffStreet",cameraData$intersection))
```

```
## [1] 0
```

```r
# more useful string functions
library(stringr)
nchar("Jeffrey Leek") # number of characters in the input string
```

```
## [1] 12
```

```r
substr("Jeffrey Leek",1,7) # substring out the input string from 1st index to 7th
```

```
## [1] "Jeffrey"
```

```r
paste("Jeffrey","Leek") # pastes two strings together
```

```
## [1] "Jeffrey Leek"
```

```r
paste0("Jeffrey","Leek") # pastes together with no whitespace between
```

```
## [1] "JeffreyLeek"
```

```r
str_trim("     Jeff     ") #trims out whitespaces bidirectionally
```

```
## [1] "Jeff"
```

```r
# important points about string/texts:
# 1) should be lowercase if possible
# 2) descriptive as opposed to mysterious variables
# 3) non-duplicative
# 4) not have "_", ".", " " if possible
# 5) should be made into factor variables (case by case)
# 6) should be descriptive (use T/F) as opposed to 0/1;
#    and "Male/Female" as opposed to 0/1 and "M/F"
```

###14) working with dates

```r
# simple example
d1<-date();d1;class(d1)
```

```
## [1] "Thu Mar 10 16:34:30 2016"
```

```
## [1] "character"
```

```r
# 'Date' class
d2<-Sys.Date();d2;class(d2)
```

```
## [1] "2016-03-10"
```

```
## [1] "Date"
```

```r
# formatting dates
# %d (days as #), %a (abbreviated weekday), %A (unabbreviated weekday)
# %m (month as #), %b (abbreviated month), %B (unabbreviated month)
# %y (2 digit year), %Y (4 digit year)
format(d2,"%a %b %d")
```

```
## [1] "Thu Mar 10"
```

```r
# creating dates
x<-c("1jan1960","2jan1960","31mar1960","30jul1960")
z<-as.Date(x,"%d%b%Y");z
```

```
## [1] "1960-01-01" "1960-01-02" "1960-03-31" "1960-07-30"
```

```r
z[2] - z[1]
```

```
## Time difference of 1 days
```

```r
as.numeric(z[2]-z[1])
```

```
## [1] 1
```

```r
# converting to Julian calendar system
weekdays(d2)
```

```
## [1] "Thursday"
```

```r
months(d2)
```

```
## [1] "March"
```

```r
# number of days since the origin of time (1970-01-01)
julian(d2)
```

```
## [1] 16870
## attr(,"origin")
## [1] "1970-01-01"
```

```r
# Lubridate package
if(!require(lubridate)){
  install.packages("lubridate",repo="https://cran.rstudio.com/")
}
library(lubridate);
ymd("20140108")
```

```
## [1] "2014-01-08 UTC"
```

```r
mdy("08/04/2013")
```

```
## [1] "2013-08-04 UTC"
```

```r
dmy("03-04-2013")
```

```
## [1] "2013-04-03 UTC"
```

```r
# Lubridate with time + date
ymd_hms("2011-08-03 10:15:03")
```

```
## [1] "2011-08-03 10:15:03 UTC"
```

```r
ymd_hms("2011-08-03 10:15:03",tz="Pacific/Auckland")
```

```
## [1] "2011-08-03 10:15:03 NZST"
```

```r
# slightly different syntax for some functions
x<-dmy(c("1jan2013","2jan2013","31mar2013","30jul2013"))
wday(x[1]); wday(x[1],label=TRUE)
```

```
## [1] 3
```

```
## [1] Tues
## Levels: Sun < Mon < Tues < Wed < Thurs < Fri < Sat
```

###15) data resources

```r
# open government sites
# United Nations:
#   http://data.un.org
# United States:
#   http:/www.data.gov
# United Kingdom:
#   http://data.gov.uk
# France:
#   http://www.data.gouv.fr
# Ghana:
#   http://data.gov.gh
# Australia:
#   http://data.gov.au
# Germany:
#   https://www.govdata.de
# Hong Kong:
#   http://www.gov.hk/en/theme/psi/datasets
# Japan:
#   http://www.data.go.jp

# Gapminder: data about development of human health
# http://www.gapminder.org

# Survey data from the United States
# http://www.asdfree.com

# Infochimps Marketplace -- some cost money
# http://www.infochimps.com/marketplace

# Kaggle -- data sets
# http://www.kaggle.com

# Collections by data scientists
# Hilary Mason:
#   http://bitly.com/bundles/hmason/1
# Peter Skomoroch
#   https://delicious.com/pksomoroch/datasets
# Jeff Hammerbacher
#   http://www.quora.com/Jeff-Hammerbacher/Introduction-to-Data-Science-Data-Sets
# Gregory Piatetsky-Shapiro
#   http://www.kdnuggets.com/gps.html
# http://blog.mortardata.com/post/67652898761/6-dataset-lists-curated-by-data-scientists

# More specialized collections:
# Stanford Large Network Data
# UCI Machine Learning
# KDD Nuggets Datasets
# CMU Statlib
# Gene Expression Omnibus
# ArXiv Data
# Public Data Sets on Amazon Web Services

# Some API's with R Interfaces
# twitter / twitterR pkg
# figshare / rfigshare
# PLoS / rplos
# rOpenSci
# Facebook / RFacebook
# Google Maps / RGoogleMaps
```
